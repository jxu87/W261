{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting customers.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile customers.dat\n",
    "1|Alice Bob|31|CA\n",
    "2|Sam Sneed|51|NV\n",
    "3|Jon Sneed|37|CA\n",
    "4|Arnold Wesise|17|NY\n",
    "5|Henry Bob|25|NV\n",
    "6|Yo Yo Ma|37|NY\n",
    "7|Jon York|41|WA\n",
    "8|Alex Ball|26|WA\n",
    "9|Jim Davis|19|CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting orders.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile orders.dat\n",
    "1|Apple\n",
    "3|Garlic\n",
    "2|Milk\n",
    "1|Iphone\n",
    "4|Ipad\n",
    "5|Book\n",
    "7|Potato\n",
    "8|Tomato\n",
    "9|Orange\n",
    "5|shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hashinnerjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRJobStep\n",
    "from mrjob.compat import get_jobconf_value\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "def csv_readline(line):\n",
    "    \"\"\"Given a sting CSV line, return a list of strings.\"\"\"\n",
    "    for row in csv.reader([line]):\n",
    "        return row\n",
    "\n",
    "class leftjoin(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRJobStep(mapper_init = self.mapper_init,\n",
    "                         mapper = self.mapper, mapper_final = self.mapper_final)]\n",
    "    \n",
    "    def mapper_init():\n",
    "        self.lefttable = {}        \n",
    "        with open('customers.dat','r') as f:\n",
    "            for line in f: \n",
    "                cell = line.split(\"|\")\n",
    "                if cell[1] not in urls.keys():\n",
    "                    self.lefttable[cell[1]] = [cell[4],[]]\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        cell = line.split(\"|\")\n",
    "        key = cell[0]\n",
    "        self.lefttable[key][1].append()\n",
    "\n",
    "    def mapper_final(self):\n",
    "        yield urls\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    leftjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (hashinnerjoin.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"hashinnerjoin.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    def mapper_final(self):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from test import leftjoin\n",
    "mr_job = leftjoin(args=['customers.dat','orders.dat'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    count = 0\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print value\n",
    "        count = count + 1\n",
    "print \"\\n\"\n",
    "print \"There are %s records\" %count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReducerSideInnerJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducersideinnerjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducersideinnerjoin.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRJobStep\n",
    "from mrjob.compat import get_jobconf_value\n",
    " \n",
    "class innerjoin(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        x = line.split(\"|\")\n",
    "        if len(x) == 4:\n",
    "            yield x[0], (\"lefttable\", x[1], x[2], x[3])\n",
    "        else:\n",
    "            yield x[0], (\"righttable\", x[1])\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        customers = list()\n",
    "        orders = list()\n",
    "        for val in values:\n",
    "            if val[0] == u'lefttable':\n",
    "                customers.append(val)\n",
    "            else:\n",
    "                orders.append(val)\n",
    "        for o in orders:\n",
    "            for c in customers:\n",
    "                yield None, [key] + c[1:] + o[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    innerjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.runner:\n",
      "WARNING:mrjob.runner:PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "WARNING:mrjob.runner:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Alice Bob', '31', 'CA', 'Apple']\n",
      "['1', 'Alice Bob', '31', 'CA', 'Iphone']\n",
      "['2', 'Sam Sneed', '51', 'NV', 'Milk']\n",
      "['3', 'Jon Sneed', '37', 'CA', 'Garlic']\n",
      "['4', 'Arnold Wesise', '17', 'NY', 'Ipad']\n",
      "['5', 'Henry Bob', '25', 'NV', 'Book']\n",
      "['5', 'Henry Bob', '25', 'NV', 'shoes']\n",
      "['7', 'Jon York', '41', 'WA', 'Potato']\n",
      "['8', 'Alex Ball', '26', 'WA', 'Tomato']\n",
      "['9', 'Jim Davis', '19', 'CA', 'Orange']\n",
      "\n",
      "\n",
      "There are 10 records\n"
     ]
    }
   ],
   "source": [
    "from reducersideinnerjoin import innerjoin\n",
    "mr_job = innerjoin(args=['customers.dat','orders.dat'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    count = 0\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print value\n",
    "        count = count + 1\n",
    "print \"\\n\"\n",
    "print \"There are %s records\" %count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReducerSideLeftJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducersideleftjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducersideleftjoin.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRJobStep\n",
    "from mrjob.compat import get_jobconf_value\n",
    " \n",
    "class leftjoin(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        x = line.split(\"|\")\n",
    "        if len(x) == 4:\n",
    "            yield x[0], (\"lefttable\", x[1], x[2], x[3])\n",
    "        else:\n",
    "            yield x[0], (\"righttable\", x[1])\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        customers = list()\n",
    "        orders = list()\n",
    "        for val in values:\n",
    "            if val[0]== u'lefttable':\n",
    "                customers.append(val)\n",
    "            else:\n",
    "                orders.append(val)\n",
    "        for c in customers:\n",
    "            if len(orders)==0:\n",
    "                yield None, [key] + c[1:] + [None] \n",
    "            for o in orders:\n",
    "                yield None, [key] + c[1:] + o[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    leftjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.runner:\n",
      "WARNING:mrjob.runner:PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "WARNING:mrjob.runner:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Alice Bob', '31', 'CA', 'Apple']\n",
      "['1', 'Alice Bob', '31', 'CA', 'Iphone']\n",
      "['2', 'Sam Sneed', '51', 'NV', 'Milk']\n",
      "['3', 'Jon Sneed', '37', 'CA', 'Garlic']\n",
      "['4', 'Arnold Wesise', '17', 'NY', 'Ipad']\n",
      "['5', 'Henry Bob', '25', 'NV', 'Book']\n",
      "['5', 'Henry Bob', '25', 'NV', 'shoes']\n",
      "['6', 'Yo Yo Ma', '37', 'NY', None]\n",
      "['7', 'Jon York', '41', 'WA', 'Potato']\n",
      "['8', 'Alex Ball', '26', 'WA', 'Tomato']\n",
      "['9', 'Jim Davis', '19', 'CA', 'Orange']\n",
      "\n",
      "\n",
      "There are 11 records\n"
     ]
    }
   ],
   "source": [
    "from reducersideleftjoin import leftjoin\n",
    "mr_job = leftjoin(args=['customers.dat','orders.dat'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    count = 0\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print value\n",
    "        count = count + 1\n",
    "print \"\\n\"\n",
    "print \"There are %s records\" %count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReducerSideRightJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducersiderightjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducersiderightjoin.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRJobStep\n",
    "from mrjob.compat import get_jobconf_value\n",
    " \n",
    "class rightjoin(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        x = line.split(\"|\")\n",
    "        if len(x) == 4:\n",
    "            yield x[0], (\"lefttable\", x[1], x[2], x[3])\n",
    "        else:\n",
    "            yield x[0], (\"righttable\", x[1])\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        customers = list()\n",
    "        orders = list()\n",
    "        for val in values:\n",
    "            if val[0]== u'lefttable':\n",
    "                customers.append(val)\n",
    "            else:\n",
    "                orders.append(val)\n",
    "        for o in orders:\n",
    "            if len(customers)==0:\n",
    "                yield None, [key] + [None, None, None] + o[1:]\n",
    "            for c in customers:\n",
    "                yield None, [key] + c[1:] + o[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rightjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.runner:\n",
      "WARNING:mrjob.runner:PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "WARNING:mrjob.runner:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Alice Bob', '31', 'CA', 'Apple']\n",
      "['1', 'Alice Bob', '31', 'CA', 'Iphone']\n",
      "['2', 'Sam Sneed', '51', 'NV', 'Milk']\n",
      "['3', 'Jon Sneed', '37', 'CA', 'Garlic']\n",
      "['4', 'Arnold Wesise', '17', 'NY', 'Ipad']\n",
      "['5', 'Henry Bob', '25', 'NV', 'Book']\n",
      "['5', 'Henry Bob', '25', 'NV', 'shoes']\n",
      "['7', 'Jon York', '41', 'WA', 'Potato']\n",
      "['8', 'Alex Ball', '26', 'WA', 'Tomato']\n",
      "['9', 'Jim Davis', '19', 'CA', 'Orange']\n",
      "\n",
      "\n",
      "There are 10 records\n"
     ]
    }
   ],
   "source": [
    "from reducersiderightjoin import rightjoin\n",
    "mr_job = rightjoin(args=['customers.dat','orders.dat'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    count = 0\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print value\n",
    "        count = count + 1\n",
    "print \"\\n\"\n",
    "print \"There are %s records\" %count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing convert.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile convert.py\n",
    "#!/usr/bin/python\n",
    "## log_preprocess_42.py\n",
    "## Author: Angela Gunn & Jing Xu\n",
    "## Description: Proprocesses log data on a single node\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    print \"No input file is passed, Aborting!!!\"\n",
    "    sys.exit(1)\n",
    "\n",
    "input_file = sys.argv[1]\n",
    "output_file = input_file + '.pp'\n",
    "\n",
    "try:\n",
    "    os.remove(output_file)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "last_visitor = None #set last visitor value to append to output file\n",
    "with open(input_file, 'r') as f1: #open input file to read\n",
    "    with open(output_file, 'a') as f2: #open ouput file to write\n",
    "        for line in f1:\n",
    "            line = line.strip()\n",
    "            tokens = line.split(\",\")\n",
    "            if len(tokens) == 3 and tokens[0] == 'C': #check for Visitor ID\n",
    "                last_visitor = tokens[2]  #set last visitor to new Visitor ID\n",
    "            if len(tokens) == 3 and tokens[0] == 'V': #check for Page ID\n",
    "                out_line = 'V,{0},C,{1}\\n'.format(tokens[1],last_visitor)\n",
    "                f2.write(out_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x convert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python convert.py anonymous-msweb.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile top_visitor_44.py\n",
    "## top_visitor_44.py\n",
    "## Author: Angela Gunn & Jing Xu\n",
    "## Description: Find most frequent visitor for each page from the log\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import csv\n",
    "\n",
    "def csv_readline(line):\n",
    "    \"\"\"Given a sting CSV line, return a list of strings.\"\"\"\n",
    "    for row in csv.reader([line]):\n",
    "        return row\n",
    "\n",
    "class TopVisitor(MRJob):\n",
    "    \n",
    "    top_page_visitor = {}\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRStep(mapper = self.mapper,\n",
    "                    combiner = self.combiner,\n",
    "                    reducer = self.reducer),\n",
    "                MRStep(reducer = self.reducer_frequent_visitor)]\n",
    "\n",
    "    def mapper(self, line_no, line):\n",
    "        #Extracts the Vroot that was visited\n",
    "        line = line.strip(' ')\n",
    "        cell = csv_readline(line)\n",
    "        yield (cell[1],cell[3]),1 \n",
    "\n",
    "    def combiner(self, key, visit_counts):\n",
    "        #combines the visits\n",
    "        total = sum(visit_counts)\n",
    "        yield key, total\n",
    "        \n",
    "    def reducer(self, key, visit_counts): #Sumarizes the visit counts by adding them together.\n",
    "        #combines the visits, and adds the key to top_page_visitor dictionary if qualified\n",
    "        total = sum(visit_counts)\n",
    "        page = key[0]\n",
    "        visitor = key[1][1:]\n",
    "        top_count = int(self.top_page_visitor.get(page,(visitor,0))[1]) #assign top_count value\n",
    "        if top_count < total:\n",
    "            self.top_page_visitor[page] = (visitor,total)        \n",
    "        yield page, total    \n",
    "    #end def reducer        \n",
    "    \n",
    "    def reducer_frequent_visitor(self, page, visit_counts):\n",
    "        with open('url.txt','r') as f:\n",
    "            for line in f:\n",
    "                cell = csv_readline(line)\n",
    "                if cell[1] == page:\n",
    "                    key = \"{0:>20}|{1:>5}|{2:>5}\".format(cell[4],page,self.top_page_visitor[page][0]) #yield top page visitor\n",
    "                    break\n",
    "        yield key, self.top_page_visitor[page][1]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    TopVisitor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x top_visitors_44.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"activities\", \"descriptions\"]\t1.0\n",
      "[\"activities\", \"events\"]\t1.0\n",
      "[\"activities\", \"facts\"]\t1.0\n",
      "[\"activities\", \"increased\"]\t1.0\n",
      "[\"activities\", \"methods\"]\t1.0\n",
      "[\"activities\", \"principles\"]\t1.0\n",
      "[\"agreement\", \"developed\"]\t1.0\n",
      "[\"agreement\", \"relations\"]\t1.0\n",
      "[\"alone\", \"cost\"]\t1.0\n",
      "[\"alteration\", \"clue\"]\t1.0\n",
      "[\"activities\", \"descriptions\"]\t1.0\n",
      "[\"activities\", \"events\"]\t1.0\n",
      "[\"activities\", \"facts\"]\t1.0\n",
      "[\"activities\", \"increased\"]\t1.0\n",
      "[\"activities\", \"methods\"]\t1.0\n",
      "[\"activities\", \"principles\"]\t1.0\n",
      "[\"agreement\", \"developed\"]\t1.0\n",
      "[\"agreement\", \"relations\"]\t1.0\n",
      "[\"alone\", \"cost\"]\t1.0\n",
      "[\"alteration\", \"clue\"]\t1.0\n",
      "    1000 top1k_test.out\n"
     ]
    }
   ],
   "source": [
    "!cat bigram_test_Jaccard_54.out | sort -k3nr  > file_test.out\n",
    "!head file_test.out\n",
    "!head -1000 file_test.out > top1k_test.out\n",
    "!head top1k_test.out\n",
    "!wc -l top1k_test.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'call_for', u'inquire', u'require', u'necessitate', u'involve', u'need', u'enquire', u'expect', u'demand', u'ask', u'postulate', u'take']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "import ast\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "\n",
    "print synonyms('ask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Length of Synonym Dict: 1007\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "import ast\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "\n",
    "total_count = 0\n",
    "correct_count = 0\n",
    "cnt_fn = 0\n",
    "\n",
    "# Load synomyn file\n",
    "dict_syn = {}\n",
    "line_cnt = 0\n",
    "with open('top1k_test.out', 'r') as f:\n",
    "    for line in f:\n",
    "        line_cnt += 1\n",
    "        if line_cnt%100 == 0: print line_cnt\n",
    "        t = line.strip().split('\\t')\n",
    "        w1 = t[0].lower()\n",
    "        w2 = t[1].lower()\n",
    "        if w1 in dict_syn.keys():\n",
    "            dict_syn[w1].append(w2)\n",
    "        else:\n",
    "            dict_syn[w1] = [w2]\n",
    "        if w2 in dict_syn.keys():\n",
    "            dict_syn[w2].append(w1)\n",
    "        else:\n",
    "            dict_syn[w2] = [w1]\n",
    "\n",
    "print \"Length of Synonym Dict: {0}\".format(len(dict_syn))\n",
    "            \n",
    "# Check if any of the top 1000 matches the synonym list\n",
    "with open('top1k_test.out', 'r') as f:\n",
    "    for line in f:\n",
    "        cnt_t += 1\n",
    "        t = line.strip().split('\\t')\n",
    "        t[1] = t[1].replace(\"\\\\\",\"\")[1:-1]\n",
    "        pair = ast.literal_eval(t[1])\n",
    "        syn0 = synonyms(pair[0].lower())\n",
    "        syn1 = synonyms(pair[1].lower())\n",
    "\n",
    "        # Precision\n",
    "        if pair[1].lower() in syn0 or pair[0].lower() in syn1:\n",
    "            print \"MATCH: {0}\".format(pair)\n",
    "            cnt_m += 1\n",
    "        \n",
    "        # Recall\n",
    "        if pair[0].lower() in dict_syn.keys() or pair[1].lower() in dict_syn.keys():\n",
    "            cnt_fn += 1\n",
    "        \n",
    "            \n",
    "print \"\\nTotal Count: {0}, TP: {1}, FP: {2}, FN: {3}\".format(cnt_t, cnt_m, cnt_t - cnt_m, cnt_fn)\n",
    "\"\"\"\n",
    "p = round(float(cnt_m) / cnt_t, 3)\n",
    "r = round(float(cnt_m) / (cnt_m + cnt_fn), 3)\n",
    "f1 = round(2 * p * r / (p + r), 3)\n",
    "\n",
    "print \"\\n### PRECISION: {0}\".format(p)\n",
    "print \"\\n### RECALL: {0}\".format(r)\n",
    "print \"\\n### F1 Score: {0}\".format(f1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Length of Synonym Dict: 1007\n",
      "MATCH: ['principles', 'rule']\n",
      "MATCH: ['added', 'supply']\n",
      "\n",
      "Total Count: 1000, TP: 2, FP: 998, FN: 0\n",
      "\n",
      "### PRECISION: 0.002\n",
      "\n",
      "### RECALL: 1.0\n",
      "\n",
      "### F1 Score: 0.004\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "import ast\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "\n",
    "cnt_t = 0\n",
    "cnt_m = 0\n",
    "cnt_fn = 0\n",
    "\n",
    "# Load synomyn file\n",
    "dict_syn = {}\n",
    "line_cnt = 0\n",
    "with open('top1k.out', 'r') as f:\n",
    "    for line in f:\n",
    "        line_cnt += 1\n",
    "        if line_cnt%100 == 0: print line_cnt\n",
    "        t = line.strip().split('\\t')\n",
    "        w1 = t[0].lower()\n",
    "        w2 = t[1].lower()\n",
    "        if w1 in dict_syn.keys():\n",
    "            dict_syn[w1].append(w2)\n",
    "        else:\n",
    "            dict_syn[w1] = [w2]\n",
    "        if w2 in dict_syn.keys():\n",
    "            dict_syn[w2].append(w1)\n",
    "        else:\n",
    "            dict_syn[w2] = [w1]\n",
    "\n",
    "print \"Length of Synonym Dict: {0}\".format(len(dict_syn))\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "# Check if any of the top 1000 matches the synonym list\n",
    "with open('top1k.out', 'r') as f:\n",
    "    for line in f:\n",
    "        cnt_t += 1\n",
    "        t = line.strip().split('\\t')\n",
    "        pair = ast.literal_eval(t[0])\n",
    "        syn0 = synonyms(pair[0].lower().strip(' '))\n",
    "        syn1 = synonyms(pair[1].lower().strip(' '))\n",
    "        # Precision\n",
    "        if pair[1].lower() in syn0 or pair[0].lower() in syn1:\n",
    "            print \"MATCH: {0}\".format(pair)\n",
    "            cnt_m += 1\n",
    "        \n",
    "        # Recall\n",
    "        if pair[0].lower() in dict_syn.keys() or pair[1].lower() in dict_syn.keys():\n",
    "            cnt_fn += 1\n",
    "        \n",
    "            \n",
    "print \"\\nTotal Count: {0}, TP: {1}, FP: {2}, FN: {3}\".format(cnt_t, cnt_m, cnt_t - cnt_m, cnt_fn)\n",
    "\n",
    "p = round(float(cnt_m) / cnt_t, 3)\n",
    "r = round(float(cnt_m) / (cnt_m + cnt_fn), 3)\n",
    "f1 = round(2 * p * r / (p + r), 3)\n",
    "\n",
    "print \"\\n### PRECISION: {0}\".format(p)\n",
    "print \"\\n### RECALL: {0}\".format(r)\n",
    "print \"\\n### F1 Score: {0}\".format(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
