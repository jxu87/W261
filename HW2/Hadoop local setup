http://sungsoo.github.io/2015/09/01/hadoop-installation-on-mac-os-x-yosemite.html

ssh JingXu@100.64.26.163

ssh localhost

ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys

ssh-keygen -t rsa -P "" â€“f $HOME/.ssh/id_rsa
cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
cat ~/.ssh/id_rsa.pub | ssh JingXu@100.64.26.163 'cat >> $HOME/.ssh/authorized_keys'
cat ~/.ssh/id_dsa.pub | ssh JingXu@100.64.26.163 'cat >> $HOME/.ssh/authorized_keys'

download and unpack hadoop distribution

/usr/libexec/java_home --> /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home

cd /Users/JingXu/Documents/hadoop-2.6.3

nano /etc/hosts

nano etc/hadoop/hadoop-env.sh
# set to the root of your Java installation
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home
# set to the root of your Hadoop installation
export HADOOP_PREFIX=/Users/JingXu/Documents/hadoop-2.6.3

nano etc/hadoop/core-site.xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>

nano etc/hadoop/hdfs-site.xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>

nano etc/hadoop/mapred-site.xml.template
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>

nano etc/hadoop/yarn-site.xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>

cd /Users/JingXu/Documents/hadoop-2.6.3

bin/hdfs namenode -format

Start namenode/datanodes/yarn:

sbin/start-dfs.sh
http://localhost:50070/
bin/hdfs dfs -mkdir /user http://localhost:50070/
bin/hdfs dfs -mkdir /user/jing
sbin/start-yarn.sh

rm -Rf /tmp/hadoop-JingXu/*

Test code:
bin/hdfs dfs -put etc/hadoop input
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.3.jar grep /user/jing /user/jing/results 'dfs[a-z.]+'

bin/hdfs dfs -get /user/jing/results
cd results
cat /user/jing/results/*

bin/hdfs dfs -put etc/hadoop /user/jing
hadoop fs -put etc/hadoop /user/jing

bin/hdfs dfs -cat /user/jing/results/*

STOP:
sbin/stop-yarn.sh
sbin/stop-dfs.sh